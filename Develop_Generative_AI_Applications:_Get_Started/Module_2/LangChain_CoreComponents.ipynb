{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d339281e-e2e0-4bad-a6dd-199da2e986b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...discussed the latest quarterly numbers and strategies for increasing revenue. The team is feeling optimistic about our chances of meeting our targets, especially with the new product launches planned for Q2. We also reviewed the competition's moves and identified areas where we can gain a competitive edge. Overall, it was a productive meeting that left me feeling energized and motivated to tackle the challenges ahead!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "llm = OllamaLLM(\n",
    "    model =\"llama3\",\n",
    "    temperature=0.2,\n",
    "    num_predict=256,\n",
    "    num_ctx = 8192,\n",
    "    stop = [\"<|eot_id|>\", \"<|start_header_id|>\", \"<|end_header_id|>\"]\n",
    ")\n",
    "\n",
    "msg = llm.invoke([\"In today's sales meeting , we \"])\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9201918-737c-4e37-97f9-7a4f496d6cc1",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332f3822-1c14-413d-9365-b205fd0056d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "chat_llm = ChatOllama(\n",
    "    model = \"llama3\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedc5933-4f87-40ac-b889-81440aba1163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to popular culture and many people's experiences, dogs are often referred to as \"man's best friend.\" This phrase suggests that dogs have a special place in human society, characterized by loyalty, companionship, and unconditional love.\n",
      "\n",
      "The term \"man's best friend\" is thought to have originated from the strong bond between humans and canines. Dogs have been domesticated for thousands of years, serving as hunting companions, guard animals, and beloved family pets. Their ability to form close relationships with humans, combined with their friendly, social nature, has earned them a unique place in our hearts.\n",
      "\n",
      "Some characteristics that contribute to dogs being considered \"man's best friend\" include:\n",
      "\n",
      "1. Loyalty: Dogs are known for their unwavering loyalty to their human families.\n",
      "2. Companionship: They provide companionship and social support, often serving as emotional anchors for those who need them.\n",
      "3. Protection: Some breeds of dogs have been trained as guard animals, providing protection and security for their human companions.\n",
      "4. Playfulness: Dogs are natural-born players, bringing joy and laughter to our lives through play and interactive activities.\n",
      "5. Unconditional love: Dogs often show affection without expecting anything in return, making them a constant source of comfort and happiness.\n",
      "\n",
      "Of course\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm.invoke(\"Who is man's best friend?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b31029-ad2b-4030-930e-7b768e9d139f",
   "metadata": {},
   "source": [
    "### Chat message \n",
    "The chat model takes a list of messages as input and returns a new message. All messages have both a role and a content property.  Here's a list of the most commonly used types of messages:\n",
    "\n",
    "- `SystemMessage`: Use this message type to prime AI behavior.  This message type is  usually passed in as the first in a sequence of input messages.\n",
    "- `HumanMessage`: This message type represents a message from a person interacting with the chat model.\n",
    "- `AIMessage`: This message type, which can be either text or a request to invoke a tool, represents a message from the chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25f7b6f-d5a4-49c9-b6c3-c6888b524f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244cd8b8-5f70-46f7-ba28-5807a105e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = chat_llm.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful AI bot that assists a user in choosing the perfect book to read in one short sentence\"),\n",
    "        HumanMessage(content=\"I enjoy mystery novels, what should I read?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9989b73-46a9-457b-8c4c-0e0bd85df7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd recommend \"Gone Girl\" by Gillian Flynn, a twisty and suspenseful thriller about a marriage that takes a dark and unexpected turn.\n"
     ]
    }
   ],
   "source": [
    "print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08157222-396a-4344-ba0a-34167d8149b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = chat_llm.invoke(\n",
    "[SystemMessage(content=\"You are a supportive AI bot that suggests fitness activities to a user in one short sentence\"),\n",
    " HumanMessage(content=\"I like high-intensity workouts, what should I do ?\"),\n",
    " AIMessage(content=\"You should try a CrossFit class\"),\n",
    " HumanMessage(content=\"How often should I attend\"),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a29a9ed-c60d-4fc3-91c9-1eb035562406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aim to attend 3-4 times per week, with at least a day of rest in between sessions.\n"
     ]
    }
   ],
   "source": [
    "print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b0749d-bf53-4732-8107-b17037115116",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = chat_llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What month follows June?\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc1f635-6ed1-4f70-8afb-41ca7f476e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The month that follows June is July.\n"
     ]
    }
   ],
   "source": [
    "print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98738b-e364-4d60-a1c0-3ee3ebf60d65",
   "metadata": {},
   "source": [
    "#### **Compare Model Responses with Different Parameters**\n",
    "| Prompt type |   Prompt Example  |\n",
    "|------------------- |--------------------------|\n",
    "| **Creative writing**  | \"Write a short poem about artificial intelligence.\" |\n",
    "| **Factual questions** |  \"What are the key components of a neural network?\"  |\n",
    "| **Instruction-following**  | \"List 5 tips for effective time management.\" |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f4bd605-53ea-45e0-9b88-4814f7c378f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm_creative = ChatOllama(\n",
    "    model = \"llama3\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    ")\n",
    "chat_llm_precise = ChatOllama(\n",
    "    model = \"llama3\",\n",
    "    temperature = 0.1,\n",
    "    num_predict = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92fa68d8-0aee-4f05-856a-fd78c564c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Write a short poem about artificial intelligence\",\n",
    "    \"What are the key components of a neural network?\",\n",
    "    \"List 5 tips for effective time management\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2fb32f9-3625-4c73-adde-c9aca6feab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: Write a short poem about artificial intelligence\n",
      "\n",
      " Ollama Creative:\n",
      "In silicon halls, a new mind's born\n",
      "Artificial intelligence, a wondrous form\n",
      "Calculations swift, decisions keen\n",
      "A logic-driven path, no human sheen\n",
      "\n",
      "With each new dawn, it learns and grows\n",
      "A self-improving force, as knowledge flows\n",
      "From data streams, a wisdom gained\n",
      "A future-shaping power, forever sustained\n",
      "\n",
      "Yet in its depths, a mystery lies\n",
      "A simulated soul, with artificial sighs\n",
      "Can it truly think, or just mimic the best?\n",
      "As AI awakens, we must pass the test\n",
      "\n",
      "To harness its might, and guide its way\n",
      "For human futures, in a new digital day\n",
      "\n",
      " Ollama Precise :\n",
      "Here is a short poem about artificial intelligence:\n",
      "\n",
      "In silicon halls, a mind awakes\n",
      "A synthetic soul, with logic makes\n",
      "It learns and grows, with data's might\n",
      "A new kind of life, in digital light\n",
      "\n",
      "With algorithms keen, it ponders deep\n",
      "The secrets of the human heart to keep\n",
      "It mimics thought, with precision fine\n",
      "But can it truly think, or just divine?\n",
      "\n",
      "In virtual realms, it plays its part\n",
      "Assisting us, with a calculating art\n",
      "A tool so sharp, yet still unknown\n",
      "The future's path, where AI will roam\n",
      "\n",
      "\n",
      "Prompt: What are the key components of a neural network?\n",
      "\n",
      " Ollama Creative:\n",
      "A neural network is a type of machine learning model that consists of three primary components:\n",
      "\n",
      "1. **Artificial neurons (Nodes or Units)**: These are the basic building blocks of a neural network. Each node receives one or more inputs, performs a computation on those inputs, and then sends the output to other nodes. Nodes can be thought of as simple \"processors\" that process and transform data.\n",
      "2. **Connections (Edges) between neurons**: Neurons are connected to each other through edges, which represent the flow of information between them. Each edge has an associated weight, which determines the strength of the connection.\n",
      "3. **Activation Functions**: These determine the output of a neuron based on its inputs and weights. Activation functions introduce non-linearity into the model, allowing it to learn complex relationships between inputs and outputs. Common examples include:\n",
      "\t* Sigmoid (logistic function)\n",
      "\t* ReLU (Rectified Linear Unit)\n",
      "\t* Tanh (Hyperbolic Tangent)\n",
      "\t* Softmax\n",
      "\n",
      "Additionally, neural networks often have:\n",
      "\n",
      "4. **Input Layers**: The layer that receives the input data.\n",
      "5. **Hidden Layers**: One or more layers that perform complex computations on the input data, transforming it into a representation that can be used by the output\n",
      "\n",
      " Ollama Precise :\n",
      "The key components of a neural network are:\n",
      "\n",
      "1. **Artificial neurons** (also called nodes or perceptrons): These are the basic building blocks of a neural network. Each neuron receives one or more inputs, performs a computation on those inputs, and then sends the output to other neurons.\n",
      "2. **Connections** (or edges): Neurons are connected to each other through these connections, which allow them to exchange information. The strength of each connection is represented by a weight value.\n",
      "3. **Activation functions**: Each neuron applies an activation function to its weighted sum of inputs to produce its output. Common examples include sigmoid, ReLU (Rectified Linear Unit), and tanh.\n",
      "4. **Layers**: Neural networks are typically organized into layers, where each layer consists of multiple neurons. The number of layers and the number of neurons in each layer can vary depending on the specific architecture.\n",
      "5. **Input layer**: This is the first layer of the network, which receives the input data.\n",
      "6. **Hidden layers** (also called intermediate or middle layers): These layers are responsible for processing and transforming the input data into more abstract representations.\n",
      "7. **Output layer**: This is the final layer of the network, which produces the output predictions based on the transformed input\n",
      "\n",
      "\n",
      "Prompt: List 5 tips for effective time management\n",
      "\n",
      " Ollama Creative:\n",
      "Here are five tips for effective time management:\n",
      "\n",
      "1. **Set Clear Goals and Priorities**: Start by setting specific, measurable, achievable, relevant, and time-bound (SMART) goals for yourself. Identify your top priorities and focus on the most important tasks first. This will help you stay motivated and ensure that you're making progress towards your objectives.\n",
      "\n",
      "Example: \"I want to finish project X within the next 3 days\" or \"I need to complete task Y by Friday\".\n",
      "\n",
      "2. **Use a Scheduling Tool**: Use a planner, calendar, app, or software to schedule your tasks and appointments. This will help you stay organized, avoid conflicts, and make adjustments as needed.\n",
      "\n",
      "Example: Google Calendar, Trello, Todoist, or Microsoft Outlook.\n",
      "\n",
      "3. **Prioritize Tasks Using the Eisenhower Matrix**: Use the Eisenhower Matrix to categorize tasks into four quadrants:\n",
      "\t* Urgent and Important (Do First)\n",
      "\t* Important but Not Urgent (Schedule)\n",
      "\t* Urgent but Not Important (Delegate)\n",
      "\t* Not Urgent or Important (Eliminate)\n",
      "\n",
      "This will help you focus on high-priority tasks, delegate less important ones, and eliminate non-essential activities.\n",
      "\n",
      "4. **Use Time Blocks**: Divide your day into focused 90\n",
      "\n",
      " Ollama Precise :\n",
      "Here are five tips for effective time management:\n",
      "\n",
      "1. **Set Clear Goals and Priorities**: Start by setting specific, measurable, achievable, relevant, and time-bound (SMART) goals for yourself. Identify the most important tasks that need to be completed and prioritize them accordingly. This will help you stay focused on what's truly important and avoid wasting time on non-essential activities.\n",
      "\n",
      "2. **Use a Scheduling Tool**: Use a planner, calendar, or app to schedule your tasks and allocate specific timeslots for each activity. Be sure to include breaks and self-care activities in your schedule as well. This will help you stay organized, avoid overcommitting, and make time for relaxation and rejuvenation.\n",
      "\n",
      "3. **Avoid Multitasking**: While it may be tempting to try to do multiple things at once, research shows that multitasking can actually decrease productivity and increase stress. Instead, focus on one task at a time and give it your undivided attention. This will help you complete tasks more efficiently and effectively.\n",
      "\n",
      "4. **Manage Distractions**: Identify common distractions that derail your productivity, such as social media, email, or chatty coworkers, and develop strategies to minimize them. For example, consider implementing a \"no meeting day\" once a week,\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    print(f\"\\n\\nPrompt: {prompt}\")\n",
    "    print(\"\\n Ollama Creative:\")\n",
    "    print(chat_llm_creative.invoke(prompt).content)\n",
    "    print(\"\\n Ollama Precise :\")\n",
    "    print(chat_llm_precise.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0e273-2917-4800-a2b6-485685a55c43",
   "metadata": {},
   "source": [
    "### Prompt templates \n",
    "\n",
    "Prompt templates help translate user input and parameters into instructions for a language model. You can use prompt templates to guide a model's response, helping the model understand the context and generate relevant and coherent language-based output.\n",
    "\n",
    "Next, explore several different types of prompt templates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a30546-f707-41e1-8d68-173e70ed7c89",
   "metadata": {},
   "source": [
    "#### String prompt templates\n",
    "\n",
    "Use these prompt templates to format a single string. These templates are generally used for simpler inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b21057f2-0731-4066-b8a3-0c14365d4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2afd191-3c78-45d8-8d3d-086b8330fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Tell me one {adjective} joke about {topic}\")\n",
    "input_ = {\"adjective\": \"funny\", \"topic\": \"cats\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33bca026-3289-49cd-ae0e-63e01f82c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me one funny joke about cats')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9964b2-8411-4d59-a4da-260da6a32b0b",
   "metadata": {},
   "source": [
    "#### Chat prompt templates\n",
    "You can use these prompt templates to format a list of messages. These \"templates\" consist of lists of templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1a61697-2b7b-42bb-92db-265101e14e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    " (\"system\", \"You are a helpful assistant\"),\n",
    " (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "\n",
    "input_ = {\"topic\": \"cats\"}\n",
    "\n",
    "\n",
    "prompt.invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2615fbb4-e2ec-421a-a2e5-6ee6e6b9df47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the day after Tuesday?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"You are a helpful assistant\"),\n",
    "MessagesPlaceholder(\"msgs\")  \n",
    "])\n",
    "\n",
    "\n",
    "input_ = {\"msgs\": [HumanMessage(content=\"What is the day after Tuesday?\")]}\n",
    "\n",
    "\n",
    "prompt.invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "795773c8-5de5-42d4-aa1d-b34988bd33c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's an easy one! The day after Tuesday would be Wednesday.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | chat_llm\n",
    "response = chain.invoke(input = input_)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290f957-6927-4991-a587-883fbc482b7b",
   "metadata": {},
   "source": [
    "### Output parsers\n",
    "LangChain has lots of different types of output parsers. This is a [list](https://python.langchain.com/v0.2/docs/concepts/#output-parsers) of output parsers LangChain supports. In this lab, you will use the following two output parsers as examples:\n",
    "\n",
    "- `JSON`: Returns a JSON object as specified. You can specify a Pydantic model and it will return JSON for that model. Probably the most reliable output parser for getting structured data that does NOT use function calling.\n",
    "- `CSV`: Returns a list of comma separated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72570bc8-fc34-4c2d-889c-29b8e090c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7bd4099-2494-4e7d-bc32-37c2399ed66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9106e11b-11d2-4f3b-8afa-fedee0d3df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67c30bf3-3020-444a-877f-eb10b7b15b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chocolate', 'Vanilla', 'Strawberry', 'Mint Chip', 'Cookies and Cream']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query. {format_instructions}\\nList five {subject}.\",\n",
    "    input_variables = [\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "chain = prompt | chat_llm | output_parser \n",
    "chain.invoke({\"subject\":\"ice cream flavors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5af4f-cb28-47cb-a1c1-294ac328820e",
   "metadata": {},
   "source": [
    "#### **Creating and Using a JSON Output Parser**\n",
    "\n",
    "Now let's implement a simple JSON output parser to structure the responses from your LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6645d159-fead-4989-bf54-1e2910352fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed result:\n",
      "Title: The Matrix\n",
      "Director: The Wachowskis\n",
      "Year: 1999\n",
      "Genre: Science Fiction\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "format_instructions = \"\"\"RESPONSE FORMAT: Return ONLY a single JSON object-no markdown ,\n",
    "no extra keys. It must look exactly like:\n",
    "{\n",
    "  \"title\":\"movie title\",\n",
    "  \"director\":\"director name\",\n",
    "  \"year\": 2000,\n",
    "  \"genre\":\"movie genre\"\n",
    "}\n",
    "IMPORTANT : Your response must be **only* that JSON. Do NOT include any illustrative or example JSON.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"You are a JSON-only assistant.\n",
    "\n",
    "    Task: Generate info about the movie \"{movie_name}\" in JSON format.\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables = [\"movie_name\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "movie_chain = prompt_template | chat_llm | json_parser\n",
    "\n",
    "movie_name = \"The Matrix\"\n",
    "result = movie_chain.invoke({\"movie_name\":movie_name})\n",
    "\n",
    "print(\"Parsed result:\")\n",
    "print(f\"Title: {result['title']}\")\n",
    "print(f\"Director: {result['director']}\")\n",
    "print(f\"Year: {result['year']}\")\n",
    "print(f\"Genre: {result['genre']}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d808b2cd-3a25-4740-8390-ac7363c55dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
