{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b9ad66-1fa5-4c4f-bf2f-765b9ab27314",
   "metadata": {},
   "source": [
    "### Python REPL \n",
    "Sometimes, for complex calculations, rather than have an LLM generate the answer directly, it can be better to have the LLM generate code to calculate the answer, and then run that code to get the answer. In order to easily do that, we provide a simple Python REPL to execute commands in.\n",
    "\n",
    "This interface will only return things that are printed - therefor, if you want to use it to calculate an answer, make sure to have it print out the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae66296-2402-4b5b-afd3-15b6ada73d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e1493b-38e1-4405-a2df-9260c4e0ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from langchain_experimental.tools import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d5cbf0-d84f-4fff-a128-17f4ec13e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# This version is pre-configured for v1.0 compatibility\n",
    "python_calculator = PythonREPLTool()\n",
    "python_calculator.name = \"python_calculator\" \n",
    "python_calculator.description = \"Calculate math or run Python code. Input: valid Python.\"\n",
    "\n",
    "# Your weather tool is already perfect\n",
    "@tool\n",
    "def search_weather(location: str):\n",
    "    \"\"\"Search for the current weather in the specified location.\"\"\"\n",
    "    return f\"The weather in {location} is currently sunny and 72Â°F.\"\n",
    "\n",
    "tools = [python_calculator, search_weather]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b992557-d5c8-46db-9f98-e16300db6631",
   "metadata": {},
   "source": [
    "##### **Toolkits**\n",
    "Toolkits are collections of tools that are designed to be used together for specific tasks.\n",
    "\n",
    "Let's create a simple toolkit that contains multiple tools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bece8a-bfb2-4d20-bb03-ad89d5a09e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toolkit (collection of tools)\n",
    "tools = [python_calculator, search_weather]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579688e-bed2-442b-8a84-0f44f3b3783d",
   "metadata": {},
   "source": [
    "##### **Agents**\n",
    "\n",
    "By themselves, language models can't take actions; they just output text. A big use case for LangChain is creating agents. Agents are systems that leverage a large language model (LLM) as a reasoning engine to identify appropriate actions and determine the required inputs for those actions. The results of those actions are to be fed back into the agent. The agent then makes a determination whether more actions are needed, or if the task is complete.\n",
    "\n",
    "The modern approach to creating agents in LangChain uses the `create_react_agent` function and `AgentExecutor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35155f72-8df8-4b99-82e4-8dfd59057baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat_llm = ChatOllama(\n",
    "    model = \"llama3.1\",\n",
    "    temperature = 0.8 ,\n",
    "    num_predict = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fbfccd-9bf9-4e14-9c06-741e93f83fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce9f97a-b862-4e08-a844-32b753d7fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new way: Just provide the instructions/persona\n",
    "system_message = \"You are a helpful research assistant. Use the Python Calculator for math.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=chat_llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_message  # No placeholders needed!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c51335b-7171-436f-8eb9-7ea45435e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['messages'])\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"input\": \"What is the square root of 256?\"})\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa6d71de-ef35-4e3f-8589-94401f483abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_message = result[\"messages\"][-1]\n",
    "print(final_message.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8653ee-dbf6-4f26-a0bf-715af75d93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2026-03-01T20:44:06.810793Z', 'done': True, 'done_reason': 'stop', 'total_duration': 289814375, 'load_duration': 89796625, 'prompt_eval_count': 62, 'prompt_eval_duration': 198710042, 'eval_count': 1, 'eval_duration': None, 'logprobs': None, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--019cab24-dff7-7b33-a5b2-bde505f3dad5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 62, 'output_tokens': 1, 'total_tokens': 63})]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5525b7f-2d5e-47ca-905a-694971c8ff35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
